{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv('data/train.csv')[['index', 'tweet', 'label']]\n",
    "# df_dev = pd.read_csv('data/dev.csv')[['index', 'tweet', 'label']]\n",
    "# df_test = pd.read_csv('data/test.csv')[['index', 'tweet', 'label']]\n",
    "\n",
    "# df_eda_aug = pd.read_csv('data/train_EDA_aug.csv')[['index', 'tweet', 'label']]\n",
    "# df_gpt_aug = pd.read_csv('data/train_EDA_aug.csv')[['index', 'tweet', 'label']]\n",
    "\n",
    "df_semeval_climate = pd.read_csv('data/semeval_climate.csv')[['index', 'tweet', 'label']]\n",
    "df_semeval_abortion = pd.read_csv('data/semeval_abortion.csv')[['index', 'tweet', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    # remove URLs\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))', '', tweet)\n",
    "    tweet = re.sub(r'http\\S+', ' ', tweet)\n",
    "    \n",
    "    # remove usernames\n",
    "    tweet = re.sub('@[^\\s]+', ' ', tweet)\n",
    "    \n",
    "    # remove the # in hashtag and split hashtags\n",
    "    tweet_toks = tweet.split(\" \")\n",
    "    final_tweet_toks = []\n",
    "    for i in range(len(tweet_toks)):\n",
    "        if tweet_toks[i].startswith(\"#\"):\n",
    "            hashtag = tweet_toks[i]\n",
    "            hashtag = hashtag[1:]\n",
    "            split_hashtag = re.findall('[0-9]+|[A-Z][a-z]+|[A-Z][A-Z]+|[a-z]+', hashtag)\n",
    "            final_tweet_toks = final_tweet_toks + split_hashtag\n",
    "        else:\n",
    "            final_tweet_toks.append(tweet_toks[i])\n",
    "    tweet = \" \".join(final_tweet_toks)\n",
    "    \n",
    "    # convert text to lower-case\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    #Remove any other punctuation\n",
    "    tweet = [char if char not in string.punctuation else ' ' for char in tweet ]\n",
    "    tweet = ''.join(tweet)\n",
    "    \n",
    "    #Remove non-ascii characters\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+', ' ', tweet)\n",
    "    \n",
    "    #Remove stopwords and emoticons from final word list\n",
    "    tokens = word_tokenize(tweet)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tweet = []\n",
    "    for w in tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_tweet.append(w)\n",
    "            \n",
    "    return ' '.join(filtered_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_url(tweet):\n",
    "    # remove URLs\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))', '', tweet)\n",
    "    tweet = re.sub(r'http\\S+', ' ', tweet)\n",
    "    return tweet\n",
    "\n",
    "def remove_username(tweet):\n",
    "    return re.sub('@[^\\s]+', ' ', tweet)\n",
    "\n",
    "def splite_hashtag(tweet):\n",
    "    # remove the # in hashtag and split hashtags\n",
    "    tweet_toks = tweet.split(\" \")\n",
    "    final_tweet_toks = []\n",
    "    for i in range(len(tweet_toks)):\n",
    "        if tweet_toks[i].startswith(\"#\"):\n",
    "            hashtag = tweet_toks[i]\n",
    "            hashtag = hashtag[1:]\n",
    "            split_hashtag = re.findall('[0-9]+|[A-Z][a-z]+|[A-Z][A-Z]+|[a-z]+', hashtag)\n",
    "            final_tweet_toks = final_tweet_toks + split_hashtag\n",
    "        else:\n",
    "            final_tweet_toks.append(tweet_toks[i])\n",
    "    tweet = \" \".join(final_tweet_toks)\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_preprocess(df):\n",
    "    df[\"tweet_remove_url\"] = df[\"tweet\"].apply(remove_url)\n",
    "    df[\"tweet_remove_username\"] = df[\"tweet\"].apply(remove_username)\n",
    "    df[\"tweet_remove_url_username\"] = df[\"tweet_remove_url\"].apply(remove_username)\n",
    "    df[\"tweet_remove_url_username_splite_hasghtag\"] = df[\"tweet_remove_url_username\"].apply(splite_hashtag)\n",
    "    df[\"tweet_remove_url_username_splite_hasghtag_lower_case\"] = df[\"tweet_remove_url_username_splite_hasghtag\"].apply(lambda tweet : tweet.lower())\n",
    "    df[\"tweet_complete_cleaning\"] = df[\"tweet\"].apply(preprocess_tweet)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semeval_climate = apply_preprocess(df_semeval_climate)\n",
    "df_semeval_abortion = apply_preprocess(df_semeval_abortion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semeval_climate.to_csv('data/semeval_climate_clean.csv')\n",
    "df_semeval_abortion.to_csv('data/semeval_abortion_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt_aug = apply_preprocess(df_gpt_aug)\n",
    "df_eda_aug = apply_preprocess(df_eda_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda_aug.to_csv('data/train_EDA_aug.csv')\n",
    "df_gpt_aug.to_csv('data/train_GPT_aug.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = apply_preprocess(df_train)\n",
    "df_dev = apply_preprocess(df_dev)\n",
    "df_test = apply_preprocess(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('data/train_clean.csv')\n",
    "df_dev.to_csv('data/dev_clean.csv')\n",
    "df_test.to_csv('data/test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'tweet', 'label', 'tweet_remove_url', 'tweet_remove_username',\n",
       "       'tweet_remove_url_username',\n",
       "       'tweet_remove_url_username_splite_hasghtag',\n",
       "       'tweet_remove_url_username_splite_hasghtag_lower_case',\n",
       "       'tweet_complete_cleaning'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
