% !TeX root=main.tex
\chapter{نتیجه‌گیری و کارهای آینده}
\thispagestyle{empty}

\section{نتیجه‌گیری}
در این پژوهش روش‌های حل مسئله تشخیص موضع مورد بررسی قرار گرفت. در فصل پنجم، با الهام‌گیری از رویکرد جستجو معماری عصبی، برای طراحی مدل تشخیص موضع یک فضا جستجو تعریف شد. سپس یک جستجو قاعده‌مند صورت گرفت. همچنین اثربخشی روش پیش‌پردازش داده، افزایش داده، رده‌بند و تابع ضرر به صورت جداگانه مورد بررسی قرار گرفت. در نهایت کدگذار
\lr{BERTweet}
و رده‌بند
\lr{CNN}
به عنوان مدل پیشنهادی معرفی شد. افرایش داده و روش پیش‌پردازش با رویکرد حذف نام کاربری توانستند نتایج مدل را به صورت معناداری بهبود بدهند. رده‌یند
\lr{CNN}
به صورت معنا داری از 
\lr{FNN}
بهتر عمل می‌کند. روش جستجو ارائه شده عملکرد خوبی در طراحی یک معماری مناسب از خود نشان داد. 

در فصل ششم، چهار پرامپت با رویکردهای متفاوت و سلسله مراتبی برای حل مسئله تشخیص موضع بدون داده‌ آموزشی معرفی شد. در مجموعه داده
\lr{ClimaConvo}
پرامپت
\lr{Few Shot + Chain of Thought + Context}
بهترین نتیجه را در مقایسه با سایر رویکردها کسب کرد. در مجموعه داده 
\lr{SemEval}
پرامپت
\lr{Zero Shot}
پیشنهادی توانست در موضوع "قانونی شدن سقط جنین (\lr{LA})" مقدار
$ 2.03 $
 درصد در مقایسه یا روش‌های دیگر
\lr{Zero Shot}
بهبود داشته باشد. آزمایش‌ها نشان دادند، نحوه پیش‌پردازش داده در عملکرد مدل زبانی بزرگ تاثیر معناداری ایجاد نمی‌کند. از آن‌جا که جمع‌آوری داده به ازای همه موضوعات به راحتی میسر نمی‌باشد، با ادامه پژوهش در این زمینه (تشخیص موضع بدون داده‌ آموزشی) می‌توان گامی در جهت استفاده از تشخیص موضع در کابردهای زندگی روزمره برداشت.
 
\section{پیشنهادها و کار‌های آینده}

برای ادامه پژوهش در مسئله تشخیص موضع با نظارت موارد زیر پیشنهاد می‌شود.
\begin{enumerate}
	\item 
در این پژوهش تنها مدل‌های کدگذار (همچون
\lr{BRET})
مورد بررسی قرار گرفتند. در ادامه پیشنهاد می‌شود عملکرد مدل‌های کدگشا همانند
\lr{GPT-2}
و کدگذار-کدگشا همچون
\lr{BART, T5}
نیز مورد مقایسه قرار بگیرد.

\item
مدل‌های مبتنی بر درخت همچون
\lr{XGBoost}
اخیرا به نتایج خوبی در مسائل رده‌بندی دست یافتند. پیشنهاد می‌شود در ادامه تحقیقات عملکرد این مدل نیز مورد بررسی قرار بگیرد. از جمله مزایای مدل‌های مبتنی بر درخت تقسیرپذیر بودن می‌باشد.

\item
برای داده‌های نامتوازن از تابع‌ ضررهای متناسب استفاده می‌شود. در این پژوهش دو تابع ضرر معروف این حوزه مورد بررسی قرار گرفت. بررسی سایر تابع‌های ضرر از جمله
\lr{dice}
پیشنهاد می‌شود. همچنین ترکیب تابع ضررهای متفاوت می‌تواند نتایج خوبی به ارمغان بیاورد.

\item در بخش کدگذار می‌توان از چندین مدل از پیش‌آموزش دیده و 
\lr{Concat}
بازنمایی کلمات مربوط به آن‌ها استفاده کرد. 

\end{enumerate}


در رویکرد بدون داده‌ آموزشی برای ادامه تحقیقات پیشنهادات زیر ارائه می‌شود.
\begin{enumerate}
	\item
	در پژوهش فعلی در پرامپت
	\lr{Few Shot} 
	نمونه‌های آموزشی به صورت تصادفی انتخاب شدند. پیشنهاد می‌شود با استفاده بازنمایی کلمات، به جای انتخاب تصادفی نمونه‌های ورودی نمونه‌هایی که بیشترین مشابهت را با ورودی فعلی دارند به عنوان نمونه آموزشی انتخاب شوند. 
		\item
		با استفاده از روش‌های 
		\lr{Prefix-Tuning}
		می‌توان با ثابت نگه‌داشتن وزن‌های مدل و تنها آموزش 1 درصد وزن‌ها، نتایج بهتری با پرامپت تولیدی به دست آورد.
		
		
		\item تغییر پرامپت به صورتی که به ازای پیشبینی کلاس نهایی به صورت مستقیم، احتمال تعلق ورودی به هر کلاس را پیشبینی کند. در ادامه با ایده‌های سلسه مراتبی دیگر می‌توان کلاس نهایی را به دست آورد. به عنوان مثال می‌توان بین خروجی چند مدل زبانی بزرگ اجتماع گرفت.

\end{enumerate}



